So nutzt Open Food Facts Logos, um Informationen Ã¼ber Lebensmittelprodukte zu erhalten

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3><strong>ğŸ§‚Eine Prise Kontext:</strong> â€Logosâ€?</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Open Food Facts ist mit etwa <strong>3 Mio. Produkten</strong> gefÃ¼llt. Jedes Produkt hat eine Verpackung, die so gestaltet ist, dass sie so viele Verbraucher wie mÃ¶glich anspricht. Zu diesem Zweck heben die Hersteller die QualitÃ¤ten ihrer Produkte mit<strong> auffÃ¤lligen und eindeutigen Symbolen</strong> hervor. Diese Symbole sind zahlreich und geben Auskunft Ã¼ber die Marke des Produkts, seine QualitÃ¤t, seine Zusammensetzung, die Art der Herstellung, in welcher Form es zu entsorgen ist, uswâ€¦&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Um alle Symbole zu vereinheitlichen und den Verbrauchern zu helfen, Produkte zu finden, die zu ihnen passen, haben <strong>verschiedene Institutionen strenge Regeln aufgestellt, damit die Hersteller ihre Produkte mit bestimmten Symbolen kennzeichnen kÃ¶nnen, die wir â€Logosâ€</strong> nennen. Es besteht also eine groÃŸe Chance ğŸ”¥, durch die Erkennung dieser Logos Daten Ã¼ber Produkte zu erhalten!</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Wie soll Open Food Facts sie erkennen? Wie immer dank einer Mischung aus Technik und Mitwirkenden!</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>RaphaÃ«l Bournhonesque, ein ehemaliger Mitarbeiter von Open Food Facts, der jetzt zum festen Team gehÃ¶rt und mein Praktikumsbetreuer ist, hatte in Robotoff* <strong>ein System entwickelt, um Logos aus Bildern zu extrahieren, sie in Vektoren umzuwandeln und die nÃ¤chsten Nachbarn jedes Vektors zu finden.</strong> Das Ziel, die Nachbarn von Logos zu finden, war <strong>es den Teilnehmern zu ermÃ¶glichen, riesige Mengen von Logos gleichzeitig Ã¼ber eine Plattform namens <a rel="noreferrer noopener" href="https://hunger.openfoodfacts.org/" target="_blank">Hunger Games</a> </strong>ğŸ˜‰ zu â€annotierenâ€ (manuell zu kategorisieren).</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Die damals verwendeten Modelle und Algorithmen lieferten jedoch nicht genÃ¼gend effiziente Ergebnisse.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Im September 2022 trat ich, ein Student der Ingenieurwissenschaften, dem Team fÃ¼r ein 6-monatiges Praktikum bei, das dem Bereich Logos gewidmet war, und ich arbeitete an der Ãœberarbeitung des gesamten Prozesses! ğŸ¥³&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:table -->
<figure class="wp-block-table"><table><tbody><tr><td><strong>* Was ist Robotoff?</strong><br><a rel="noreferrer noopener" href="https://github.com/openfoodfacts/robotoff" target="_blank">Robotoff</a> ist ein von Mitwirkenden entwickelter Dienst, der die Verarbeitung von Open Food Facts-Daten unterstÃ¼tzt. Ziel ist es, auf der Grundlage der bereits in der Datenbank vorhandenen Daten so viele Informationen wie mÃ¶glich zu den einzelnen Produkten abzurufen und diese in die Datenbank aufzunehmen. Derzeit stammen die von Robotoff vorgenommenen Aktualisierungen aus der Bildanalyse, durch optische Zeichenerkennung oder allgemeinere Computer-Vision-Modelle. Einige Aktualisierungen werden automatisch in die Datenbank Ã¼bernommen, andere mÃ¼ssen manuell durch Fragen oder Hunger Games validiert werden.<br><br><em><strong>Wenn Sie mehr Ã¼ber Robotoff erfahren mÃ¶chten, schauen Sie <a rel="noreferrer noopener" href="https://github.com/openfoodfacts/robotoff#readme" target="_blank">hier</a>!</strong></em> ğŸ‘€</td></tr></tbody></table></figure>
<!-- /wp:table -->

<!-- wp:heading {"level":3} -->
<h3><strong>ğŸ«— Ein Hauch von Technik: </strong>Wie funktioniert die Verarbeitung von Logos genau?</h3>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4><em>1ï¸âƒ£ </em>Logos aus Produktfotos extrahieren:</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Open Food Facts contributors trained a Machine Learning model to recognize logos in images. We put an image as the input of the model and we receive multiple bounding boxes with corresponding scores and classes. The classes on which the model was trained were â€œbrandâ€ and â€œlabelâ€.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can find the code where the model is called here: <a href="https://github.com/openfoodfacts/robotoff/blob/b209707cc062310b51f9886c87ee14be91527644/robotoff/workers/tasks/import_image.py#L325" target="_blank" rel="noreferrer noopener">Robotoff.import_image.py</a>.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can try it by using the following API :&nbsp;<a href="https://robotoff.openfoodfacts.net/api/v1/images/predict?image_url=[image_url]&amp;models=universal-logo-detector" target="_blank" rel="noreferrer noopener">https://robotoff.openfoodfacts.net/api/v1/images/predict?image_url=[image_url]&amp;models=universal-logo-detector</a></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>With the bounding boxes, you can see what are the corresponding logos with the API: <a href="https://robotoff.openfoodfacts.net/api/v1/images/crop?image_url=[image_url]&amp;y_min=[y_min]&amp;x_min=[x_min]&amp;y_max=[y_max]&amp;x_max=[x_max]" target="_blank" rel="noreferrer noopener">https://robotoff.openfoodfacts.net/api/v1/images/crop?image_url=[image_url]&amp;y_min=[y_min]&amp;x_min=[x_min]&amp;y_max=[y_max]&amp;x_max=[x_max]</a> where the coordinates are in the same order as the ones returned by the model in the bounding boxes.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Here is an example of what happens when using these APIs with the following image:</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><a href="https://images.openfoodfacts.org/images/products/322/982/012/9488/front_fr.194.400.jpg" target="_blank" rel="noreferrer noopener">https://images.openfoodfacts.org/images/products/322/982/012/9488/front_fr.194.400.jpg</a></p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":3425,"width":806,"height":252,"sizeSlug":"large","linkDestination":"none"} -->
<figure class="wp-block-image size-large is-resized"><img src="https://blog.openfoodfacts.org/wp-content/uploads/2023/02/Screenshot-2023-02-14-at-14.34.51-1024x321.png" alt="" class="wp-image-3425" width="806" height="252"/></figure>
<!-- /wp:image -->

<!-- wp:heading {"level":4} -->
<h4><em>2ï¸âƒ£ </em>Convert logos images to Vectors:</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Now that we can access logos, we need to vectorise them</strong>. For that, we use a pre-trained model from OpenAI called <a href="https://huggingface.co/docs/transformers/model_doc/clip" target="_blank" rel="noreferrer noopener">CLIP</a>. Even though the model was initially trained to match images with text, we use only the â€œcomputer visionâ€ part of the model to get the embeddings (=logos embedded in a vector space) computed by CLIP for each logo.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>We thus have a logo image as input and a vector of dimension 512 as output. The smaller the distance between two vectors is, the more similar the two corresponding logos are.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>The <a href="https://github.com/openfoodfacts/robotoff/blob/b209707cc062310b51f9886c87ee14be91527644/robotoff/workers/tasks/import_image.py#L398" target="_blank" rel="noreferrer noopener">save_logo_embeddings</a> function in Robotoff is in charge of applying the model to logos and save embeddings to the Robotoff postgresql database.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can find a more explicit code <a href="https://github.com/openfoodfacts/openfoodfacts-ai/blob/develop/logo-ann/generation/02_generate_embeddings.py#L108" target="_blank" rel="noreferrer noopener">here</a> to understand how we use CLIP to generate logos embeddings.</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":4} -->
<h4><em>3ï¸âƒ£ </em>Find nearest neighbours:</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>To find the nearest neighbors of a logo, we use an â€œindexâ€ to store the embeddings. Once this index is built, we could use the <strong>â€œbrute forceâ€ ğŸ’ª method which consists in computing the distance between the query logo and all the other logos of the db and return the closest ones</strong>. Thatâ€™s the most precise method as it gives us the â€œtrueâ€ nearest neighbors. However, this method is too slow to be applied. The time needed to extract the nearest neighbors for each logo when the total amount of logos is 2.5M is around 3s ğŸ˜´</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>As we needed a better search time and were ok with having less precision, we decided to use <strong>an approximate method</strong>. The one that Robotoff uses is called HNSW (hierarchical navigable small world). You can take a look at <a rel="noreferrer noopener" href="https://www.pinecone.io/learn/vector-indexes/" target="_blank">this article</a> to understand better nearest neighbours search.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Using a HNSW ElasticSearch index, Robotoff is now able to look for the nearest neighbours of each embedding among more than 2.5M vectors with a huge precision (more than 90% of the 100 nearest neighbours returned are among the exact 100 true nearest neighbours) and a short search time of less than 100ms ğŸ‘ğŸ‘ğŸ‘ğŸ‘.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can use the following API to get the nearest neighbours of a logo: <a href="https://robotoff.openfoodfacts.org/api/v1/ann/search/[logo_id]?count=[count]">https://robotoff.openfoodfacts.org/api/v1/ann/search/[logo_id]?count=[count]</a></p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3><strong>ğŸ¯ A spoon of contributions: </strong>Where is it used?</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>No automatic logo categorization is yet implemented in Robotoff. Everything I explained before is made only for <a href="https://hunger.openfoodfacts.org/">Hunger Games</a>.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Was ist das? It is <strong>an annotation platform </strong>developed by a contributor named Alexandre Fauquette which <strong>allows everyone to answer check predictions made by Robotoff and to categorise logos</strong>.&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><br>You can try it. A quick introduction/tutorial will welcome you and you will be able to annotate logos ! ğŸ˜‰<br>A video tutorial of â€œHow to use Hunger Games ?â€ should be out soonâ€¦ â³</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":3433,"width":505,"height":633,"sizeSlug":"full","linkDestination":"custom"} -->
<figure class="wp-block-image aligncenter size-full is-resized"><a href="hunger.openfoodfacts.org"><img src="https://blog.openfoodfacts.org/wp-content/uploads/2023/02/Screenshot-2023-02-14-at-14.44.23.png" alt="" class="wp-image-3433" width="505" height="633"/></a><figcaption class="wp-element-caption">To play the Hunger Games: hunger.openfoodfacts.org</figcaption></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p><strong>Annotating logos enhance Open Food Facts as it grows the amount of data we have on products and its quality.</strong> And thanks to the models and algorithms used in the background, you can be way more powerful and have a greater impact on people daily alimentation ğŸ¥°.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Article by Gabriel</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"left","id":3418,"width":167,"height":167,"sizeSlug":"full","linkDestination":"none"} -->
<figure class="wp-block-image alignleft size-full is-resized"><img src="https://blog.openfoodfacts.org/wp-content/uploads/2023/02/Gabriel.png" alt="" class="wp-image-3418" width="167" height="167"/></figure>
<!-- /wp:image -->
