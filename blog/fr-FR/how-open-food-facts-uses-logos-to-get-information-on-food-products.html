Comment Open Food Facts utilise les logos pour obtenir des informations produits

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3><strong>ğŸ§‚Une pincÃ©e de contexte :</strong> â€œlogosâ€ ?</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Open Food Facts contient environ <strong>3 millions de produits</strong>. Chaque produit est enrobÃ© dans un emballage conÃ§u pour Ãªtre aussi attractif que possible. Ã€ cette fin, les producteurs mettent en valeur les qualitÃ©s de leurs produits avec des <strong>symboles criards et explicites</strong>. Il existe de nombreux symboles diffÃ©rents fournissant des informations sur la marque, la qualitÃ©, la composition, les conditions de fabrication, ses consignes de recyclage, etcâ€¦&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Pour homogÃ©nÃ©iser les symboles et aider les consommateurs Ã  trouver les produits qui leur conviennent, <strong>plusieurs institutions ont Ã©ditÃ© des rÃ¨gles strictes contraignant les producteurs Ã  signaler leurs produits avec des symboles spÃ©cifiques, les "logos"</strong>. C'est une formidable opportunitÃ© ğŸ”¥ de rÃ©colter des donnÃ©es en dÃ©tectant ces logos !</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Comment devraient-ils Ãªtre reconnus par Open Food Facts ? Par un mÃ©lange de technologie et de contributions humaines, comme toujours !</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>RaphaÃ«l Bournhonesque, ancien bÃ©nÃ©vole Open Food Facts dÃ©sormais membre de l'Ã©quipe permanente qui m'a supervisÃ© en stage, avait dÃ©veloppÃ© sur Robotoff* <strong>un systÃ¨me pour extraire les logos d'une image donnÃ©e, les convertir en images vectorielles et trouver leurs cousins les plus proches.</strong> Le but Ã©tait de <strong>permettre Ã  nos contributeurs d'annoter (catÃ©goriser manuellement) d'Ã©normes quantitÃ©s de logos en mÃªme temps Ã  travers la plateforme <a rel="noreferrer noopener" href="https://hunger.openfoodfacts.org/" target="_blank">Hunger Games</a> </strong>ğŸ˜‰.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Toutefois, les modÃ¨les et algorithmes utilisÃ©s ne fournissaient pas de rÃ©sultats suffisamment efficaces.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>En septembre 2022, je menais des Ã©tudes d'ingÃ©nierie. J'ai rejoint l'Ã©quipe pour un stage de 6 mois dÃ©diÃ©s aux logos, et j'ai travaillÃ© Ã  rÃ©implÃ©menter tout ce processus ! ğŸ¥³&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:table -->
<figure class="wp-block-table"><table><tbody><tr><td><strong>* Qu'est-ce que Robotoff ?</strong><br><a rel="noreferrer noopener" href="https://github.com/openfoodfacts/robotoff" target="_blank">Robotoff</a> est un service dÃ©veloppÃ© par nos contributeurs pour aider Ã  traiter les donnÃ©es d'Open Food Facts. D'aprÃ¨s les donnÃ©es dÃ©jÃ  disponibles dans la base de donnÃ©es, l'objectif est de rÃ©cupÃ©rer autant d'informations que possible sur chaque produits et de les ajouter Ã  la base de donnÃ©es. Actuellement, les mises Ã  jour Robotoff s'appuient sur l'analyse d'images Ã  travers la reconnaissance optique de caractÃ¨res ou d'autres modÃ¨les de vision par ordinateur plus gÃ©nÃ©raux. Some updates are applied automatically to the db but some others need manual validation via questions or Hunger Games.<br><br><em><strong>To know more about Robotoff, take a look <a rel="noreferrer noopener" href="https://github.com/openfoodfacts/robotoff#readme" target="_blank">here</a>!</strong></em> ğŸ‘€</td></tr></tbody></table></figure>
<!-- /wp:table -->

<!-- wp:heading {"level":3} -->
<h3><strong>ğŸ«— A drizzle of tech: </strong>How does logos processing work exactly ?</h3>
<!-- /wp:heading -->

<!-- wp:heading {"level":4} -->
<h4><em>1ï¸âƒ£ </em>Extract logos from products images:</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Open Food Facts contributors trained a Machine Learning model to recognize logos in images. We put an image as the input of the model and we receive multiple bounding boxes with corresponding scores and classes. The classes on which the model was trained were â€œbrandâ€ and â€œlabelâ€.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can find the code where the model is called here: <a href="https://github.com/openfoodfacts/robotoff/blob/b209707cc062310b51f9886c87ee14be91527644/robotoff/workers/tasks/import_image.py#L325" target="_blank" rel="noreferrer noopener">Robotoff.import_image.py</a>.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can try it by using the following API :&nbsp;<a href="https://robotoff.openfoodfacts.net/api/v1/images/predict?image_url=[image_url]&amp;models=universal-logo-detector" target="_blank" rel="noreferrer noopener">https://robotoff.openfoodfacts.net/api/v1/images/predict?image_url=[image_url]&amp;models=universal-logo-detector</a></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>With the bounding boxes, you can see what are the corresponding logos with the API: <a href="https://robotoff.openfoodfacts.net/api/v1/images/crop?image_url=[image_url]&amp;y_min=[y_min]&amp;x_min=[x_min]&amp;y_max=[y_max]&amp;x_max=[x_max]" target="_blank" rel="noreferrer noopener">https://robotoff.openfoodfacts.net/api/v1/images/crop?image_url=[image_url]&amp;y_min=[y_min]&amp;x_min=[x_min]&amp;y_max=[y_max]&amp;x_max=[x_max]</a> where the coordinates are in the same order as the ones returned by the model in the bounding boxes.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Here is an example of what happens when using these APIs with the following image:</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><a href="https://images.openfoodfacts.org/images/products/322/982/012/9488/front_fr.194.400.jpg" target="_blank" rel="noreferrer noopener">https://images.openfoodfacts.org/images/products/322/982/012/9488/front_fr.194.400.jpg</a></p>
<!-- /wp:paragraph -->

<!-- wp:image {"id":3425,"width":806,"height":252,"sizeSlug":"large","linkDestination":"none"} -->
<figure class="wp-block-image size-large is-resized"><img src="https://blog.openfoodfacts.org/wp-content/uploads/2023/02/Screenshot-2023-02-14-at-14.34.51-1024x321.png" alt="" class="wp-image-3425" width="806" height="252"/></figure>
<!-- /wp:image -->

<!-- wp:heading {"level":4} -->
<h4><em>2ï¸âƒ£ </em>Convert logos images to Vectors:</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Now that we can access logos, we need to vectorise them</strong>. For that, we use a pre-trained model from OpenAI called <a href="https://huggingface.co/docs/transformers/model_doc/clip" target="_blank" rel="noreferrer noopener">CLIP</a>. Even though the model was initially trained to match images with text, we use only the â€œcomputer visionâ€ part of the model to get the embeddings (=logos embedded in a vector space) computed by CLIP for each logo.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>We thus have a logo image as input and a vector of dimension 512 as output. The smaller the distance between two vectors is, the more similar the two corresponding logos are.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>The <a href="https://github.com/openfoodfacts/robotoff/blob/b209707cc062310b51f9886c87ee14be91527644/robotoff/workers/tasks/import_image.py#L398" target="_blank" rel="noreferrer noopener">save_logo_embeddings</a> function in Robotoff is in charge of applying the model to logos and save embeddings to the Robotoff postgresql database.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can find a more explicit code <a href="https://github.com/openfoodfacts/openfoodfacts-ai/blob/develop/logo-ann/generation/02_generate_embeddings.py#L108" target="_blank" rel="noreferrer noopener">here</a> to understand how we use CLIP to generate logos embeddings.</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":4} -->
<h4><em>3ï¸âƒ£ </em>Find nearest neighbours:</h4>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>To find the nearest neighbors of a logo, we use an â€œindexâ€ to store the embeddings. Once this index is built, we could use the <strong>â€œbrute forceâ€ ğŸ’ª method which consists in computing the distance between the query logo and all the other logos of the db and return the closest ones</strong>. Thatâ€™s the most precise method as it gives us the â€œtrueâ€ nearest neighbors. However, this method is too slow to be applied. The time needed to extract the nearest neighbors for each logo when the total amount of logos is 2.5M is around 3s ğŸ˜´</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>As we needed a better search time and were ok with having less precision, we decided to use <strong>an approximate method</strong>. The one that Robotoff uses is called HNSW (hierarchical navigable small world). You can take a look at <a rel="noreferrer noopener" href="https://www.pinecone.io/learn/vector-indexes/" target="_blank">this article</a> to understand better nearest neighbours search.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Using a HNSW ElasticSearch index, Robotoff is now able to look for the nearest neighbours of each embedding among more than 2.5M vectors with a huge precision (more than 90% of the 100 nearest neighbours returned are among the exact 100 true nearest neighbours) and a short search time of less than 100ms ğŸ‘ğŸ‘ğŸ‘ğŸ‘.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>You can use the following API to get the nearest neighbours of a logo: <a href="https://robotoff.openfoodfacts.org/api/v1/ann/search/[logo_id]?count=[count]">https://robotoff.openfoodfacts.org/api/v1/ann/search/[logo_id]?count=[count]</a></p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3><strong>ğŸ¯ A spoon of contributions: </strong>Where is it used?</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>No automatic logo categorization is yet implemented in Robotoff. Everything I explained before is made only for <a href="https://hunger.openfoodfacts.org/">Hunger Games</a>.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Qu'est-ce donc ? It is <strong>an annotation platform </strong>developed by a contributor named Alexandre Fauquette which <strong>allows everyone to answer check predictions made by Robotoff and to categorise logos</strong>.&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><br>You can try it. A quick introduction/tutorial will welcome you and you will be able to annotate logos ! ğŸ˜‰<br>A video tutorial of â€œHow to use Hunger Games ?â€ should be out soonâ€¦ â³</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"center","id":3433,"width":505,"height":633,"sizeSlug":"full","linkDestination":"custom"} -->
<figure class="wp-block-image aligncenter size-full is-resized"><a href="hunger.openfoodfacts.org"><img src="https://blog.openfoodfacts.org/wp-content/uploads/2023/02/Screenshot-2023-02-14-at-14.44.23.png" alt="" class="wp-image-3433" width="505" height="633"/></a><figcaption class="wp-element-caption">To play the Hunger Games: hunger.openfoodfacts.org</figcaption></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p><strong>Annotating logos enhance Open Food Facts as it grows the amount of data we have on products and its quality.</strong> And thanks to the models and algorithms used in the background, you can be way more powerful and have a greater impact on people daily alimentation ğŸ¥°.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Article by Gabriel</p>
<!-- /wp:paragraph -->

<!-- wp:image {"align":"left","id":3418,"width":167,"height":167,"sizeSlug":"full","linkDestination":"none"} -->
<figure class="wp-block-image alignleft size-full is-resized"><img src="https://blog.openfoodfacts.org/wp-content/uploads/2023/02/Gabriel.png" alt="" class="wp-image-3418" width="167" height="167"/></figure>
<!-- /wp:image -->
